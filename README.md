# Building RAG Agents with LLMs

# Docs References

- https://python.langchain.com/docs/integrations/providers/nvidia/
- Models: https://build.nvidia.com/models?filters=nimType%3Anim_type_run_anywhere
- https://pypi.org/project/langchain-nvidia-ai-endpoints/0.0.4rc1/

# Objective Learinig

- **LLM Services**
- **LangChain**
- **Running State Chains**
- **Document Loading**
- **Embeddings**
- **Document Retrieval**
- **RAG Evaluation**


# Whats is RAG?

- **Retrieval**: Tool runs algorithms (database, code execution, sematic search, return a constant value, etc) to provide context.

- **Augmented**: Based on tool responses, the software pipeline systhesizes some "context" to feed to LLM w/ question.

- **Generation**: Based on question, instructions, and enhanced context, the LLM returns a response.

