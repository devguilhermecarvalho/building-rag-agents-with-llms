# Building RAG Agents with LLMs

# Docs References

- https://python.langchain.com/docs/integrations/providers/nvidia/
- Models: https://build.nvidia.com/models?filters=nimType%3Anim_type_run_anywhere
- https://pypi.org/project/langchain-nvidia-ai-endpoints/0.0.4rc1/

# Objective Learning

- **LLM Services**
- **LangChain**
- **Running State Chains**
- **Document Loading**
- **Embeddings**
- **Document Retrieval**
- **RAG Evaluation**


# What is RAG?

- **Retrieval**: Tool runs algorithms (database, code execution, semantic search, return a constant value, etc.) to provide context.

- **Augmented**: Based on tool responses, the software pipeline synthesizes some "context" to feed to the LLM with the question.

- **Generation**: Based on the question, instructions, and enhanced context, the LLM returns a response.

